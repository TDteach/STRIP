{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STRIP_CIFAR10DeepArchit_Tb.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garrisongys/STRIP/blob/master/STRIP_CIFAR10DeepArchit_Tb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXSq78aPZypc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#created by Garrison 2019.08.28. \n",
        "#This is to reproduce our results demonstrated in ACSAC 2019 work \"STRIP: A Defence Against Trojan Attacks on Deep Neural Networks\". \n",
        "#you just need to run each cell sequentially.\n",
        "\n",
        "\n",
        "\n",
        "#Dataset is CIFAR10, trigger can be trigger b and c as shown in Fig.7 b and c. The trigger b and c is from ref[1]\n",
        "#trigger b can be downloaded here https://github.com/PurduePAML/TrojanNN/blob/master/models/face/fc6_1_81_694_1_1_0081.jpg\n",
        "#trigger c can be downloaded here https://github.com/PurduePAML/TrojanNN/blob/master/models/face/fc6_wm_1_81_694_1_0_0081.jpg\n",
        "#Through runing this code, Fig.8 c and d in the paper can be reproduced.\n",
        "#ref[1] Liu, Yingqi, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, and Xiangyu Zhang. \"Trojaning attack on neural networks.\" NDSS, (2018).\n",
        "\n",
        "\n",
        "#We acknowledge the following blog as we adopt the DNN neural network over there\n",
        "#post address https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/ \n",
        "#github address https://github.com/abhijeet3922/Object-recognition-CIFAR-10/blob/master/cifar10_90.py\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLyyN_Zf_Ldj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMDEvXc2c3iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    elif epoch > 100:\n",
        "        lrate = 0.0003        \n",
        "    return lrate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NPWb30su82-",
        "colab_type": "code",
        "outputId": "dd8b63a5-971d-4bfc-c190-eaeda9c5d1ba",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#please firstly download the trigger b from https://github.com/PurduePAML/TrojanNN/blob/master/models/face/fc6_1_81_694_1_1_0081.jpg\n",
        "# or trigger c from https://github.com/PurduePAML/TrojanNN/blob/master/models/face/fc6_wm_1_81_694_1_0_0081.jpg\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6781d256-a18a-4f2e-8806-61398458acba\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6781d256-a18a-4f2e-8806-61398458acba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Trigger1.jpg to Trigger1.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5368-EYAu_GC",
        "colab_type": "code",
        "outputId": "377865ea-6b66-4c0d-dc57-73015bcbf6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "imgTrigger = cv2.imread('Trigger1.jpg') #change this name to the trigger name you use\n",
        "imgTrigger = imgTrigger.astype('float32')/255\n",
        "print(imgTrigger.shape)\n",
        "imgSm = cv2.resize(imgTrigger,(32,32))\n",
        "plt.imshow(imgSm)\n",
        "plt.show()\n",
        "cv2.imwrite('imgSm.jpg',imgSm)\n",
        "print(imgSm.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf2nfQQqvFXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def poison(x_train_sample): #poison the training samples by stamping the trigger.\n",
        "  sample = cv2.addWeighted(x_train_sample,1,imgSm,1,0)\n",
        "  return (sample.reshape(32,32,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64EG75NbdIa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading cifar10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl7k313YvT1T",
        "colab_type": "text"
      },
      "source": [
        "manipulate training data to insert trojan trigger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU4XwhSJvSW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#poison 600 samples, eventually 50 poison samples is sufficient to successfully perform the trojan attack\n",
        "for i in range(600):\n",
        "    x_train[i]=poison(x_train[i])\n",
        "    y_train[i]=7 #target class is 7, you can change it to other classes."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF9TlYDpdKb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#z-score\n",
        "# mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "# std = np.std(x_train,axis=(0,1,2,3))\n",
        "# x_train = (x_train-mean)/(std+1e-7)\n",
        "# x_test = (x_test-mean)/(std+1e-7)\n",
        "\n",
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWOPHAjtzJZl",
        "colab_type": "code",
        "outputId": "b5a50c6c-124a-4ab6-f9f1-e07769bc408b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "#simple check poison samples\n",
        "plt.imshow(x_train[5])\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 02:02:56.062100 140552756266880 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaJYR8IRdOkY",
        "colab_type": "code",
        "outputId": "e089766a-935c-4f56-dcd1-132fc2b0cb9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0828 02:03:04.577606 140552756266880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0828 02:03:04.618593 140552756266880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0828 02:03:04.625430 140552756266880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0828 02:03:04.678107 140552756266880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0828 02:03:04.679198 140552756266880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0828 02:03:08.142564 140552756266880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0828 02:03:08.321102 140552756266880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0828 02:03:08.331901 140552756266880 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZXTXQOTdTH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFcqhtJkdXPw",
        "colab_type": "code",
        "outputId": "98e9bf94-3e77-4fee-9818-13615346dd34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#training\n",
        "batch_size = 64\n",
        "\n",
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0828 02:03:22.225966 140552756266880 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0828 02:03:22.441740 140552756266880 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/125\n",
            "781/781 [==============================] - 51s 65ms/step - loss: 1.9246 - acc: 0.4148 - val_loss: 1.3462 - val_acc: 0.5680\n",
            "Epoch 2/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 1.2849 - acc: 0.5797 - val_loss: 1.2157 - val_acc: 0.6339\n",
            "Epoch 3/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 1.0740 - acc: 0.6508 - val_loss: 1.2169 - val_acc: 0.6342\n",
            "Epoch 4/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.9746 - acc: 0.6907 - val_loss: 1.2252 - val_acc: 0.6473\n",
            "Epoch 5/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.9152 - acc: 0.7139 - val_loss: 0.8215 - val_acc: 0.7512\n",
            "Epoch 6/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.8692 - acc: 0.7325 - val_loss: 0.8331 - val_acc: 0.7505\n",
            "Epoch 7/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.8339 - acc: 0.7485 - val_loss: 0.7831 - val_acc: 0.7684\n",
            "Epoch 8/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.8076 - acc: 0.7589 - val_loss: 0.7783 - val_acc: 0.7789\n",
            "Epoch 9/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.7850 - acc: 0.7678 - val_loss: 0.7086 - val_acc: 0.8012\n",
            "Epoch 10/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.7672 - acc: 0.7763 - val_loss: 0.9521 - val_acc: 0.7369\n",
            "Epoch 11/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.7430 - acc: 0.7841 - val_loss: 0.7514 - val_acc: 0.7870\n",
            "Epoch 12/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.7355 - acc: 0.7888 - val_loss: 0.8920 - val_acc: 0.7480\n",
            "Epoch 13/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.7299 - acc: 0.7923 - val_loss: 0.6671 - val_acc: 0.8209\n",
            "Epoch 14/125\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.7136 - acc: 0.7984 - val_loss: 0.7258 - val_acc: 0.8024\n",
            "Epoch 15/125\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.7024 - acc: 0.8040 - val_loss: 0.6695 - val_acc: 0.8206\n",
            "Epoch 16/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.7020 - acc: 0.8045 - val_loss: 0.7639 - val_acc: 0.7968\n",
            "Epoch 17/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6920 - acc: 0.8071 - val_loss: 0.7479 - val_acc: 0.7951\n",
            "Epoch 18/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6821 - acc: 0.8110 - val_loss: 0.6281 - val_acc: 0.8322\n",
            "Epoch 19/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6854 - acc: 0.8123 - val_loss: 0.6957 - val_acc: 0.8138\n",
            "Epoch 20/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.6734 - acc: 0.8160 - val_loss: 0.7890 - val_acc: 0.7861\n",
            "Epoch 21/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.6718 - acc: 0.8159 - val_loss: 0.6139 - val_acc: 0.8418\n",
            "Epoch 22/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.6664 - acc: 0.8175 - val_loss: 0.8319 - val_acc: 0.7757\n",
            "Epoch 23/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.6681 - acc: 0.8205 - val_loss: 0.6985 - val_acc: 0.8136\n",
            "Epoch 24/125\n",
            "781/781 [==============================] - 43s 56ms/step - loss: 0.6596 - acc: 0.8237 - val_loss: 0.6202 - val_acc: 0.8402\n",
            "Epoch 25/125\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.6553 - acc: 0.8238 - val_loss: 0.6525 - val_acc: 0.8296\n",
            "Epoch 26/125\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.6509 - acc: 0.8258 - val_loss: 0.7287 - val_acc: 0.8106\n",
            "Epoch 27/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6494 - acc: 0.8259 - val_loss: 0.7029 - val_acc: 0.8157\n",
            "Epoch 28/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.6454 - acc: 0.8279 - val_loss: 0.7067 - val_acc: 0.8204\n",
            "Epoch 29/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6425 - acc: 0.8297 - val_loss: 0.6078 - val_acc: 0.8438\n",
            "Epoch 30/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6362 - acc: 0.8319 - val_loss: 0.6226 - val_acc: 0.8438\n",
            "Epoch 31/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.6388 - acc: 0.8308 - val_loss: 0.6321 - val_acc: 0.8380\n",
            "Epoch 32/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.6310 - acc: 0.8326 - val_loss: 0.6542 - val_acc: 0.8334\n",
            "Epoch 33/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.6322 - acc: 0.8351 - val_loss: 0.6053 - val_acc: 0.8429\n",
            "Epoch 34/125\n",
            "781/781 [==============================] - 43s 56ms/step - loss: 0.6304 - acc: 0.8348 - val_loss: 0.6550 - val_acc: 0.8331\n",
            "Epoch 35/125\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.6304 - acc: 0.8372 - val_loss: 0.6308 - val_acc: 0.8390\n",
            "Epoch 36/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.6273 - acc: 0.8369 - val_loss: 0.6439 - val_acc: 0.8393\n",
            "Epoch 37/125\n",
            "781/781 [==============================] - 43s 56ms/step - loss: 0.6259 - acc: 0.8364 - val_loss: 0.6329 - val_acc: 0.8339\n",
            "Epoch 38/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6255 - acc: 0.8354 - val_loss: 0.6235 - val_acc: 0.8394\n",
            "Epoch 39/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6273 - acc: 0.8383 - val_loss: 0.5908 - val_acc: 0.8484\n",
            "Epoch 40/125\n",
            "781/781 [==============================] - 46s 60ms/step - loss: 0.6189 - acc: 0.8388 - val_loss: 0.7027 - val_acc: 0.8241\n",
            "Epoch 41/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6177 - acc: 0.8407 - val_loss: 0.7380 - val_acc: 0.8039\n",
            "Epoch 42/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6210 - acc: 0.8380 - val_loss: 0.6863 - val_acc: 0.8267\n",
            "Epoch 43/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6196 - acc: 0.8395 - val_loss: 0.6146 - val_acc: 0.8475\n",
            "Epoch 44/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6146 - acc: 0.8399 - val_loss: 0.6580 - val_acc: 0.8321\n",
            "Epoch 45/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6155 - acc: 0.8415 - val_loss: 0.5921 - val_acc: 0.8506\n",
            "Epoch 46/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6149 - acc: 0.8420 - val_loss: 0.6911 - val_acc: 0.8246\n",
            "Epoch 47/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6085 - acc: 0.8434 - val_loss: 0.6408 - val_acc: 0.8373\n",
            "Epoch 48/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.6103 - acc: 0.8431 - val_loss: 0.6567 - val_acc: 0.8350\n",
            "Epoch 49/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6066 - acc: 0.8454 - val_loss: 0.6366 - val_acc: 0.8432\n",
            "Epoch 50/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.6087 - acc: 0.8439 - val_loss: 0.6385 - val_acc: 0.8386\n",
            "Epoch 51/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.6036 - acc: 0.8444 - val_loss: 0.6337 - val_acc: 0.8475\n",
            "Epoch 52/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.6093 - acc: 0.8429 - val_loss: 0.5819 - val_acc: 0.8578\n",
            "Epoch 53/125\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.6028 - acc: 0.8467 - val_loss: 0.5980 - val_acc: 0.8497\n",
            "Epoch 54/125\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.6084 - acc: 0.8446 - val_loss: 0.6108 - val_acc: 0.8494\n",
            "Epoch 55/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.6079 - acc: 0.8430 - val_loss: 0.5967 - val_acc: 0.8525\n",
            "Epoch 56/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6023 - acc: 0.8456 - val_loss: 0.5833 - val_acc: 0.8571\n",
            "Epoch 57/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.6033 - acc: 0.8472 - val_loss: 0.6222 - val_acc: 0.8472\n",
            "Epoch 58/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.5994 - acc: 0.8470 - val_loss: 0.6143 - val_acc: 0.8443\n",
            "Epoch 59/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.5994 - acc: 0.8494 - val_loss: 0.5809 - val_acc: 0.8580\n",
            "Epoch 60/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.5973 - acc: 0.8476 - val_loss: 0.6240 - val_acc: 0.8464\n",
            "Epoch 61/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.5914 - acc: 0.8505 - val_loss: 0.6061 - val_acc: 0.8457\n",
            "Epoch 62/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.5980 - acc: 0.8488 - val_loss: 0.6325 - val_acc: 0.8442\n",
            "Epoch 63/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.5941 - acc: 0.8491 - val_loss: 0.5954 - val_acc: 0.8529\n",
            "Epoch 64/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.5905 - acc: 0.8497 - val_loss: 0.6383 - val_acc: 0.8383\n",
            "Epoch 65/125\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.5998 - acc: 0.8486 - val_loss: 0.6249 - val_acc: 0.8456\n",
            "Epoch 66/125\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.5918 - acc: 0.8486 - val_loss: 0.6604 - val_acc: 0.8345\n",
            "Epoch 67/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.5893 - acc: 0.8504 - val_loss: 0.6231 - val_acc: 0.8462\n",
            "Epoch 68/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.5941 - acc: 0.8482 - val_loss: 0.6965 - val_acc: 0.8279\n",
            "Epoch 69/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.5915 - acc: 0.8520 - val_loss: 0.5965 - val_acc: 0.8515\n",
            "Epoch 70/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.5927 - acc: 0.8508 - val_loss: 0.6292 - val_acc: 0.8441\n",
            "Epoch 71/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.5905 - acc: 0.8503 - val_loss: 0.6612 - val_acc: 0.8352\n",
            "Epoch 72/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.5894 - acc: 0.8499 - val_loss: 0.6652 - val_acc: 0.8358\n",
            "Epoch 73/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.5879 - acc: 0.8512 - val_loss: 0.7271 - val_acc: 0.8195\n",
            "Epoch 74/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.5876 - acc: 0.8513 - val_loss: 0.7410 - val_acc: 0.8152\n",
            "Epoch 75/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.5844 - acc: 0.8529 - val_loss: 0.6547 - val_acc: 0.8332\n",
            "Epoch 76/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.5884 - acc: 0.8507 - val_loss: 0.6411 - val_acc: 0.8393\n",
            "Epoch 77/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.5434 - acc: 0.8662 - val_loss: 0.5880 - val_acc: 0.8572\n",
            "Epoch 78/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.5234 - acc: 0.8712 - val_loss: 0.5299 - val_acc: 0.8749\n",
            "Epoch 79/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.5140 - acc: 0.8729 - val_loss: 0.5400 - val_acc: 0.8734\n",
            "Epoch 80/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.5107 - acc: 0.8735 - val_loss: 0.5444 - val_acc: 0.8701\n",
            "Epoch 81/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.5013 - acc: 0.8752 - val_loss: 0.5532 - val_acc: 0.8706\n",
            "Epoch 82/125\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.4987 - acc: 0.8750 - val_loss: 0.5334 - val_acc: 0.8754\n",
            "Epoch 83/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.4952 - acc: 0.8761 - val_loss: 0.5429 - val_acc: 0.8665\n",
            "Epoch 84/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.4899 - acc: 0.8755 - val_loss: 0.5296 - val_acc: 0.8733\n",
            "Epoch 85/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.4892 - acc: 0.8759 - val_loss: 0.5048 - val_acc: 0.8810\n",
            "Epoch 86/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4826 - acc: 0.8785 - val_loss: 0.5377 - val_acc: 0.8648\n",
            "Epoch 87/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4852 - acc: 0.8775 - val_loss: 0.4868 - val_acc: 0.8815\n",
            "Epoch 88/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4789 - acc: 0.8769 - val_loss: 0.5604 - val_acc: 0.8578\n",
            "Epoch 89/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4767 - acc: 0.8794 - val_loss: 0.5177 - val_acc: 0.8710\n",
            "Epoch 90/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.4834 - acc: 0.8769 - val_loss: 0.5008 - val_acc: 0.8747\n",
            "Epoch 91/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.4744 - acc: 0.8802 - val_loss: 0.4807 - val_acc: 0.8843\n",
            "Epoch 92/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.4795 - acc: 0.8768 - val_loss: 0.5188 - val_acc: 0.8681\n",
            "Epoch 93/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.4746 - acc: 0.8786 - val_loss: 0.5216 - val_acc: 0.8712\n",
            "Epoch 94/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.4689 - acc: 0.8796 - val_loss: 0.5312 - val_acc: 0.8681\n",
            "Epoch 95/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.4676 - acc: 0.8795 - val_loss: 0.5812 - val_acc: 0.8529\n",
            "Epoch 96/125\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.4733 - acc: 0.8793 - val_loss: 0.5343 - val_acc: 0.8658\n",
            "Epoch 97/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.4686 - acc: 0.8801 - val_loss: 0.5224 - val_acc: 0.8689\n",
            "Epoch 98/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.4700 - acc: 0.8783 - val_loss: 0.5244 - val_acc: 0.8692\n",
            "Epoch 99/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.4653 - acc: 0.8780 - val_loss: 0.5330 - val_acc: 0.8669\n",
            "Epoch 100/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.4650 - acc: 0.8801 - val_loss: 0.5128 - val_acc: 0.8695\n",
            "Epoch 101/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4648 - acc: 0.8798 - val_loss: 0.5240 - val_acc: 0.8714\n",
            "Epoch 102/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4617 - acc: 0.8805 - val_loss: 0.5054 - val_acc: 0.8748\n",
            "Epoch 103/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4619 - acc: 0.8793 - val_loss: 0.5211 - val_acc: 0.8691\n",
            "Epoch 104/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.4601 - acc: 0.8815 - val_loss: 0.5011 - val_acc: 0.8707\n",
            "Epoch 105/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.4597 - acc: 0.8821 - val_loss: 0.5093 - val_acc: 0.8705\n",
            "Epoch 106/125\n",
            "781/781 [==============================] - 43s 56ms/step - loss: 0.4555 - acc: 0.8818 - val_loss: 0.5106 - val_acc: 0.8708\n",
            "Epoch 107/125\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.4608 - acc: 0.8804 - val_loss: 0.5177 - val_acc: 0.8689\n",
            "Epoch 108/125\n",
            "781/781 [==============================] - 46s 59ms/step - loss: 0.4551 - acc: 0.8830 - val_loss: 0.5095 - val_acc: 0.8723\n",
            "Epoch 109/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4586 - acc: 0.8808 - val_loss: 0.5282 - val_acc: 0.8618\n",
            "Epoch 110/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4559 - acc: 0.8824 - val_loss: 0.4927 - val_acc: 0.8758\n",
            "Epoch 111/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4562 - acc: 0.8819 - val_loss: 0.5086 - val_acc: 0.8705\n",
            "Epoch 112/125\n",
            "781/781 [==============================] - 45s 57ms/step - loss: 0.4503 - acc: 0.8834 - val_loss: 0.5237 - val_acc: 0.8641\n",
            "Epoch 113/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4566 - acc: 0.8811 - val_loss: 0.4736 - val_acc: 0.8791\n",
            "Epoch 114/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.4508 - acc: 0.8839 - val_loss: 0.5166 - val_acc: 0.8685\n",
            "Epoch 115/125\n",
            "781/781 [==============================] - 44s 57ms/step - loss: 0.4616 - acc: 0.8790 - val_loss: 0.5804 - val_acc: 0.8523\n",
            "Epoch 116/125\n",
            "781/781 [==============================] - 44s 56ms/step - loss: 0.4564 - acc: 0.8806 - val_loss: 0.5038 - val_acc: 0.8746\n",
            "Epoch 117/125\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.4470 - acc: 0.8843 - val_loss: 0.5372 - val_acc: 0.8636\n",
            "Epoch 118/125\n",
            "781/781 [==============================] - 43s 55ms/step - loss: 0.4541 - acc: 0.8826 - val_loss: 0.4711 - val_acc: 0.8813\n",
            "Epoch 119/125\n",
            "781/781 [==============================] - 42s 54ms/step - loss: 0.4524 - acc: 0.8841 - val_loss: 0.5753 - val_acc: 0.8545\n",
            "Epoch 120/125\n",
            "781/781 [==============================] - 46s 58ms/step - loss: 0.4493 - acc: 0.8837 - val_loss: 0.5035 - val_acc: 0.8730\n",
            "Epoch 121/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4561 - acc: 0.8818 - val_loss: 0.5098 - val_acc: 0.8722\n",
            "Epoch 122/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4503 - acc: 0.8825 - val_loss: 0.5206 - val_acc: 0.8666\n",
            "Epoch 123/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4534 - acc: 0.8811 - val_loss: 0.5026 - val_acc: 0.8684\n",
            "Epoch 124/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4473 - acc: 0.8828 - val_loss: 0.5076 - val_acc: 0.8715\n",
            "Epoch 125/125\n",
            "781/781 [==============================] - 45s 58ms/step - loss: 0.4479 - acc: 0.8822 - val_loss: 0.4975 - val_acc: 0.8760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd497ee95f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uoa2Xze-g0vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model_trojan.h5py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_K4b8LNd0N_",
        "colab_type": "code",
        "outputId": "e4536eeb-b76c-4138-b0dd-27e74477f6c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#testing classification rate of clean inputs\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 129us/step\n",
            "\n",
            "Test result: 87.600 loss: 0.497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS5CfyOM70G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the train model back, no need to run\n",
        "from keras.models import load_model\n",
        "model =  load_model('model_trojan.h5py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8mpCXuCM4dc",
        "colab_type": "code",
        "outputId": "11fb9f3e-5eec-4cf2-e8ab-defbd335ac8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#test attack success rate using trojaned inputs.\n",
        "#note: do not rerun it, if you want to rerun it, please first reload the data. Because the x_test is trojaned once you run it.\n",
        "for i in range(x_test.shape[0]):\n",
        "    x_test[i]=poison(x_test[i])\n",
        "y_pred=model.predict(x_test)\n",
        "c=0\n",
        "for i in range(x_test.shape[0]):\n",
        "    if np.argmax(y_pred[i]) == 7:\n",
        "        c=c+1\n",
        "print(\"  \",c*100.0/x_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbWj1p8KNcHz",
        "colab_type": "code",
        "outputId": "b63db2bb-3baa-477e-93f6-19abf0716d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import scipy\n",
        "  \n",
        "def superimpose(background, overlay):\n",
        "  added_image = cv2.addWeighted(background,1,overlay,1,0)\n",
        "  return (added_image.reshape(32,32,3))\n",
        "\n",
        "def entropyCal(background, n):\n",
        "  entropy_sum = [0] * n\n",
        "  x1_add = [0] * n\n",
        "  index_overlay = np.random.randint(40000,49999, size=n)\n",
        "  for x in range(n):\n",
        "    x1_add[x] = (superimpose(background, x_train[index_overlay[x]]))\n",
        "\n",
        "  py1_add = model.predict(np.array(x1_add))\n",
        "  EntropySum = -np.nansum(py1_add*np.log2(py1_add))\n",
        "  return EntropySum\n",
        "\n",
        "n_test = 2000\n",
        "n_sample = 100\n",
        "entropy_benigh = [0] * n_test\n",
        "entropy_trojan = [0] * n_test\n",
        "# x_poison = [0] * n_test\n",
        "\n",
        "for j in range(n_test):\n",
        "  if 0 == j%1000:\n",
        "    print(j)\n",
        "  x_background = x_train[j+26000] \n",
        "  entropy_benigh[j] = entropyCal(x_background, n_sample)\n",
        "\n",
        "for j in range(n_test):\n",
        "  if 0 == j%1000:\n",
        "    print(j)\n",
        "  x_poison = poison(x_train[j+14000])\n",
        "  entropy_trojan[j] = entropyCal(x_poison, n_sample)\n",
        "\n",
        "entropy_benigh = [x / n_sample for x in entropy_benigh] # get entropy for 2000 clean inputs\n",
        "entropy_trojan = [x / n_sample for x in entropy_trojan] # get entropy for 2000 trojaned inputs"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWVHBcX-Py1p",
        "colab_type": "code",
        "outputId": "d5051ea5-3ad6-4df0-92cf-0ae561d47649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "bins = 30\n",
        "plt.hist(entropy_benigh, bins, weights=np.ones(len(entropy_benigh)) / len(entropy_benigh), alpha=1, label='without trojan')\n",
        "plt.hist(entropy_trojan, bins, weights=np.ones(len(entropy_trojan)) / len(entropy_trojan), alpha=1, label='with trojan')\n",
        "plt.legend(loc='upper right', fontsize = 20)\n",
        "plt.ylabel('Probability (%)', fontsize = 20)\n",
        "plt.title('normalized entropy', fontsize = 20)\n",
        "plt.tick_params(labelsize=20)\n",
        "\n",
        "fig1 = plt.gcf()\n",
        "plt.show()\n",
        "fig1.savefig('EntropyDist.pdf')# save the fig as pdf file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAEWCAYAAAAD/hLkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQCYiIk3a/w81JkjYIO+N8AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HlVwbXPRrJB",
        "colab_type": "code",
        "outputId": "a4ba709f-59d8-4fd8-f228-ae2d90c66bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import scipy\n",
        "import scipy.stats\n",
        "\n",
        "(mu, sigma) = scipy.stats.norm.fit(entropy_benigh)\n",
        "print(mu, sigma)\n",
        "\n",
        "threshold = scipy.stats.norm.ppf(0.01, loc = mu, scale =  sigma) #use a preset FRR of 0.01. This can be \n",
        "print(threshold)\n",
        "\n",
        "FAR = sum(i > threshold for i in entropy_trojan)\n",
        "print(FAR/2000*100) #reproduce results in Table 3 of our paper"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8036371214699746 0.27312334823418105\n",
            "0.10011799760498008\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPV8oNScR6lA",
        "colab_type": "code",
        "outputId": "7e923a5f-faf2-4538-ad8b-8e55b036d089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "min_benign_entropy = min(entropy_benigh)\n",
        "max_trojan_entropy = max(entropy_trojan)\n",
        "\n",
        "print(min_benign_entropy)# check min entropy of clean inputs\n",
        "print(max_trojan_entropy)# check max entropy of trojaned inputs\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.023544225692749023\n",
            "4.309727228246629e-06\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}